{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pipeline Deployment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have trained our models for feature engineering and binary classification, we can choose to deploy them in pipeline using Amazon SageMaker Inference Pipelines.\n",
    "\n",
    "This notebook demonstrates how to create a pipeline with the SKLearn model for feature engineering and the Amazon SageMaker Linear Learner model for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "print(region)\n",
    "print(role)\n",
    "\n",
    "# Replace username placeholder.\n",
    "username = '[username]'\n",
    "bucket_name = '{0}-sm-workshop-lux'.format(username)\n",
    "prefix = '05'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create SageMaker Model objects, which represent the objects that binds together the artifacts of training (model artifacts as S3 objects) and the Docker container used for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to specify the paths to our models in S3 (you can get the path by looking at the S3 output path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_preprocessor_path = 's3://{0}/{1}/output/pred-main-prep-skl-{2}-[timestamp]/output/model.tar.gz'.format(bucket_name, prefix, username)\n",
    "linear_learner_model_path = 's3://{0}/{1}/output/pred-main-train-ll-{2}-[timestamp]/output/model.tar.gz'.format(bucket_name, prefix, username)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to find the linear learner Docker containers path in ECR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "linear_learner_container = get_image_uri(boto3.Session().region_name, 'linear-learner', repo_version=\"latest\")\n",
    "print(linear_learner_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to create our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "sklearn_preprocessor = SKLearnModel(sklearn_preprocessor_path, role, \n",
    "                                    '1-predmain-expprep-sklearn-script.py', sagemaker_session=sagemaker_session)\n",
    "linear_learner_model = Model(linear_learner_model_path, linear_learner_container, sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have models ready, we can deploy them in a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import time\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "\n",
    "pipeline_model_name = 'predmain-sk-ll-pipeline-{0}'.format(username)\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=pipeline_model_name, \n",
    "    role=role,\n",
    "    models=[\n",
    "        sklearn_preprocessor, \n",
    "        linear_learner_model],\n",
    "    sagemaker_session=sagemaker_session)\n",
    "\n",
    "endpoint_name = 'pred-main-endp-{0}-'.format(username) + str(int(time.time()))\n",
    "print(endpoint_name)\n",
    "pipeline_model.deploy(initial_instance_count=1, \n",
    "                      instance_type='ml.m5.xlarge', \n",
    "                      endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Getting inferences</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try invoking our pipeline of models and try getting some inferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=csv_serializer,\n",
    "    content_type=CONTENT_TYPE_CSV,\n",
    "    accept=CONTENT_TYPE_JSON)\n",
    "\n",
    "payload = 'TID008,VAWT,64,95,46.0,21,55,55,7,34,NE'\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cleanup</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished testing the endpoint and getting some inferences, we can delete the endopoint to avoid incurring in unexpected charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
